---
title: "Vision Over Incidents and Claims - An Analysis"
author: "Brayden Tang, Merve Sahin, Simardeep Kaur, Xugang Zhong"
date: "29/06/2020"
output:
  html_document:
    theme: lumen
    css: "style.css"
runtime: shiny
bibliography: ref.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = here::here())
library(brms)
library(shiny)
library(reticulate)
library(kableExtra)
library(tidyverse)
library(plotly)
library(ggthemes)
library(leaflet)
library(mapview)
library(lubridate)
library(htmlwidgets)
library(shinydashboard)
library(shinycssloaders)
library(RColorBrewer)
library(sjmisc)
library(readxl)
library(wordcloud)
library(DT)
library(ggwordcloud)
library(wordcloud2)
library(PubMedWordcloud)
library(png)
library(grid)
```

## Introduction {.tabset .tabset-fade}

With the largest transit service area in Canada, TransLink is operating more than 245 bus routes and 79 kilometers of rapid transit to meet the transportation needs of 2.5 million people in Metro Vancouver as of the end of 2018 (TransLink 2018). Legislation requires TransLink to carry a $1 million per occurrence liability policy on each of its revenue vehicles and a $200,000 per occurrence liability policy on each of its non-revenue vehicles. Since 2014/2015, the premium paid to ICBC has increased by over 200% to cover onboard passenger injuries, cyclist injuries, pedestrian injuries, and losses from collisions with third party vehicles. For at-fault physical damage losses to its vehicles, the premium paid to its own captive insurance company has increased by 33%.

In response to soaring insurance costs and road safety concerns, TransLink has asked us to analyze key variables of interest that may be predictive of bus incidents. These variables include bus operator characteristics (such as work experience), bus characteristics (such as bus model and bus age), weather and time related variables, and various other factors unique to TransLink, like the bus line. Finally, TransLink has also asked us to analyze the types of claims that are occurring - in particular, if there are common types of claims per location and if particular locations yield large paid costs. 

A variety of statistical and machine learning methods are employed in this report to address these questions. As a result, the report is divided into six sections:

1) Executive Summary
2) Predictive Power of Location and Operator Experience
3) A Combined Analysis of All Factors Using Machine Learning
4) Common Types of Claims by Location
5) Assessment of Claims Costs by Location
6) Future Analysis

Finally, this report makes use of the following nomenclature:

`incident`: This is a reported collision or injury (involving a TransLink operated bus) that has **possibly** led to a claim (that may or may not produce an actual cost to TransLink). Examples include a bus collision leading to a broken mirror, a pedestrian being struck on the sidewalk by a bus, or a passenger on a bus falling over due to a wide turn taken by the operator. In general, we use this term only in a predictive context to distinguish from `claims` specific information (which can only be known after an incident has occurred). The idea is that if we try to reduce the number of incidents we directly reduce the number of claims, and therefore, insurance costs to TransLink.

`claim`: This is an actual insurance claim reported (with a known or unknown cost to TransLink) which is **always the result of an incident**. Therefore, because this is the **result** of an incident occurring there is nothing predictive about anything involving the analysis of anything claims related, such as the analysis on claim descriptions or on claim costs. 

`loss year`, `loss date`: There is a natural time lag between when an incident actually occurs, and when a claim relating to that incident is actually reported. The `loss year` and `loss date` reflect the time in which an incident actually occurred. 

### Executive Summary

### Predictive Power of Location and Operator Experience

```{r Operator Analysis: Import, include = FALSE}
# This is just helper code - do not show in report
best_bayes_model <- readRDS("results/operators/models/best-bayes-model.rds")
posterior_predictions <- readRDS("results/operators/report-tables/posterior_samples.rds")
results <- readRDS("results/operators/report-tables/validation-results.rds")
posterior_samples <- as_tibble(posterior_predictions$posterior_samples, .name_repair = "unique") %>% set_names(seq(1, ncol(.), 1))

predictor_combinations <- posterior_predictions$variables %>%
  mutate(
    experience = as.character(experience),
    cost_centre = as.character(cost_centre)
    )
predictor_combinations$experience <- ifelse(predictor_combinations$experience == ">6 & 18 Months", ">6 & <18 Months", predictor_combinations$experience)
rm(posterior_predictions)
marginal_plot <- conditional_effects(best_bayes_model, probs = c(0.05, 0.95))[[1]] %>%
  select(effect1__, estimate__, lower__, upper__) %>%
  set_names(c("Effect", "Estimate", "Lower", "Upper")) %>%
  mutate(Effect = as.character(Effect)) %>%
  mutate(Effect = as.factor(ifelse(Effect == ">6 & 18 Months", ">6 & <18 Months", Effect))) %>%
  mutate(Effect = fct_relevel(Effect, c("<6 Months", ">6 & <18 Months", ">18 & <60 Months", ">60 Months")))
random_effects <- ranef(best_bayes_model, summary = FALSE)$cost_centre
pop_effect <- fixef(best_bayes_model, summary = FALSE) 
calculate_plotting_stats <- function(col_num) {
  if (col_num == 1) {
    data_re <- as_tibble(pop_effect[, 1] + random_effects[, , 1])
  } else {
    data_re <- as_tibble(pop_effect[, 1] + random_effects[, , 1] + pop_effect[, col_num] + random_effects[, , col_num])
  }
  plotting_data <- tibble(
      `Cost Centre` = colnames(random_effects[, , col_num]),
      Estimate = round(exp(apply(data_re, 2,  FUN = median)), 3),
      `90% CI` = paste0("90% CI: ", '[', round(exp(apply(data_re, 2, FUN = function(x) quantile(x, 0.05))), 3), ', ', round(exp(apply(data_re, 2, FUN = function(x) quantile(x, 0.95))), 3), ']'),
      `Lower 5%` = round(exp(apply(data_re, 2, FUN = function(x) quantile(x, 0.05))), 3),
      `Upper 95%` = round(exp(apply(data_re, 2, FUN = function(x) quantile(x, 0.95))), 3)
    ) %>%
    mutate(`Cost Centre` = fct_reorder(`Cost Centre`, Estimate, min))
  if (col_num == 1) {
    pop_effect_opt <- tibble(`Overall Estimate Over all Cost Centres` = round(exp(median(pop_effect[, 1])), 3))
  } else {
    pop_effect_opt <- tibble(`Overall Estimate Over all Cost Centres` = round(exp(median(pop_effect[, 1] + pop_effect[, col_num])), 3))
  }
  list(plot_data = plotting_data, vline = pop_effect_opt)
}
```

<center> <h4>TransLink Hypotheses</h4> </center>

TransLink have proposed two specific hypotheses regarding a possible link between the operator's experience level and how many incidents they are involved in within a year. One such hypothesis proposed by TransLink is that newer operators have a higher tendency to get into more accidents.

The second hypothesis TransLink specifically proposed is the idea that more experienced bus operators become complacent over time as they gain more experience. Those who just exit the probationary period (operators with less than 695 hours of driving experience), for example, may become more relaxed with an increased job security and therefore may get into more incidents. 

<center> <h4>The Dataset and Overall Model</h4> </center>

A random sample of the first five rows of the analyzed dataset is given below.

```{r Operator Analysis: Sample Dataset, echo = FALSE, include = FALSE}

operators_dataset <- read_csv("results/operators/data/train.csv") %>%
  sample_n(5) %>%
  select(experience, in_probation, cost_centre, total_hours_last3yr, number_incidents, number_preventables, incidents_year, preventables_year) %>%
  rename(Experience = experience, `Cost Centre` = cost_centre, `In Probation` = in_probation, `Total Hours Worked in Last 3 Yr` = total_hours_last3yr, `Incidents/Yr` = incidents_year, `Preventables/Yr` = preventables_year, `Number of Incidents` = number_incidents, `Number of Preventables` = number_preventables)
```

```{r Operator Analysis: Sample Dataset (show), echo = FALSE}
operators_dataset %>%  
  kable() %>%
  kable_styling()
```

There are some issues with this dataset that encourages the use of non-standard statistical methods. For one, there are no operators recorded that have exactly zero incidents in the last three years - in order for an operator to appear in this dataset, they must have had at least one preventable or non-preventable incident. Therefore, using standard techniques that do not take this into consideration will lead to possibly incorrect conclusions. Second, the data is naturally grouped by cost centre. Operators who work in similar regions will therefore naturally be correlated.

Therefore, we decided to fit a Bayesian model that allows the user to control for the two problems above. The performance of this model ended up being much superior to a rather simple linear model, where the Bayesian model outperforms the simple linear model by roughly `r round(((results$MAE[1] - results$MAE[2]) / results$MAE[1]) * 100, 0)`%. Note that we did not include "In Probation" as a variable in the model since this variable carries the exact same information as the experience level. Finally, the model is adjusted to take into consideration how many hours a particular operator actually worked (since an operator who works more will naturally have more incidents).

<center> <h4>Analyzing the Effect of Location and Experience Level</h4> </center>

The interactive graph below allows the user to see the estimated number of incidents per year per each experience level or per each cost centre as estimated by the Bayesian model. These two graphs depict the exact same information but from different perspectives. It should be stressed that these are the estimated **average** number of incidents per year over all operators in a specific cost centre, with a specific experience level. These are **not** predictions (see next section) for any single operator.

```{r Operator Analysis: Marginal Effects, echo = FALSE, warning = FALSE}
tabsetPanel(
  tabPanel("Effect Per Experience Level on Incidents/Yr", selectInput("experience_oa_re", label = "Experience:", 
            choices = unique(predictor_combinations$experience), selected = ">60 Months"), plotlyOutput("re_plot")),
  tabPanel("Effect Per Cost Centre on Incidents/Yr",
           selectInput(
             "cost_centre_oa_re",
             label = "Cost Centre:",
             choices = c(unique(predictor_combinations$cost_centre), "All Cost Centres"),
             selected = "All"),
  plotlyOutput("fe_plot"))
)
output$fe_plot <- renderPlotly({
  
  cost_centre_sel <- input$cost_centre_oa_re
  if (cost_centre_sel != "All Cost Centres") {
      intercept <- pop_effect[, 1] + random_effects[, cost_centre_sel, 1]
      effects_per_centre <- cbind(intercept, intercept + pop_effect[, 2:4] + random_effects[, cost_centre_sel, 2:4])
  } else {
    intercept <- pop_effect[, 1]
    effects_per_centre <- cbind(intercept, (pop_effect + intercept)[, 2:4])
  }
  plot_cost_sel <- tibble(
    Estimate = round(exp(apply(effects_per_centre, 2, median)), 3),
    Experience = as.factor(c(">60 Months", "<6 Months", ">18 & <60 Months", ">6 Months & <18 Months")),
    `90% CI` = paste0("90% CI: ", '[', round(exp(apply(effects_per_centre, 2, function(x) quantile(x, 0.05))), 3), ', ', round(exp(apply(effects_per_centre, 2, function(x) quantile(x, 0.95))), 3), ']'),
    `Lower 5%` = round(exp(apply(effects_per_centre, 2, function(x) quantile(x, 0.05))), 3),
    `Upper 95%` = round(exp(apply(effects_per_centre, 2, function(x) quantile(x, 0.95))), 3)
  ) %>%
    mutate(Experience = fct_relevel(Experience, c("<6 Months", ">6 Months & <18 Months", ">18 & <60 Months", ">60 Months")))
    
  
  ggplotly(ggplot(plot_cost_sel, aes(x = Experience, y = Estimate, ymin = `Lower 5%`, ymax = `Upper 95%`, text = `90% CI`)) +
  geom_point() + 
  geom_errorbar(aes(ymin = `Lower 5%`, ymax = `Upper 95%`)) +
  theme_bw() +
  theme(plot.title = element_text(vjust = 5)) + 
  labs(x = "Experience Level", y = "Estimated Incidents/Yr", title = paste0("Estimated Incidents/Yr Per Experience", "<br>", "<sup>", "Cost Centre: ", cost_centre_sel, "</sup>")), width = 800, autosize = TRUE, tooltip = c("Estimate", "90% CI"))
  
  })
output$re_plot <- renderPlotly({
  if (input$experience_oa_re == ">60 Months") {
    
    plotting_data <- calculate_plotting_stats(1)
    
  } else if (input$experience_oa_re == "<6 Months") {
    
    plotting_data <- calculate_plotting_stats(2)
    
  } else if (input$experience_oa_re == ">18 & <60 Months") {
    
    plotting_data <- calculate_plotting_stats(3)
    
  } else {
    
    plotting_data <- calculate_plotting_stats(4)
    
  }
  
  ggplotly(ggplot(plotting_data[[1]], aes(x = `Cost Centre`, y = Estimate, ymin = `Lower 5%`, ymax = `Upper 95%`, text = `90% CI`)) +
    geom_point() + 
    geom_errorbar(aes(ymin = `Lower 5%`, ymax = `Upper 95%`), width = 0) +
    geom_hline(data = plotting_data[[2]], aes(yintercept = `Overall Estimate Over all Cost Centres`), color = "red") + 
    coord_flip() +
    labs(y = "Estimated Incidents/Yr", title = paste0("Estimated Cost Centre Effects for: ", input$experience_oa_re, "<br>", "<sup>", "Global Estimate in Red", "</sup>"), x = 0) + 
    theme_bw() +
    theme(axis.title.y = element_blank()), tooltip = c("Estimate", "90% CI", "Overall Estimate Over all Cost Centres")) 
  
  })
```

The user can hover their mouse over each dot to see a tool tip that provides more detailed information regarding the expected incidents per each year. One of the elements in the tool tip is labelled `90% CI` which is a 90% credible interval - in other words, there is **exactly** a 90% chance that the true average number of incidents per year (for the chosen experience level and cost centre) falls in the given range. Therefore, the larger the bars/range the greater the amount of uncertainty in the estimate, either due to a lack of data or a large variation in operator behavior. Finally, the estimated overall average over all cost centres is represented by the red vertical line.

In terms of the two original hypotheses by TransLink, it is clear that in most cases, those who are more experienced on average are expected to have fewer incidents per year. The effect is very intuitive especially for something like Vancouver in which the effect decreases in a way we would expect as an operator moves through each experience level. However, this trend is not the same for all cost centres. Port Coquitlam (PTC) is a notable exception, in which operators who have experience in the range of >18 and <60 Months have noticeably larger expected incidents per year than those with experience in the range of >6 Months & <18 Months. Furthermore, these operators with am experience level in the range of >18 and <60 Months have much larger expected incidents per year when compared to the global, overall average but for all other experience levels Port Coquitlam does not exhibit any abnormal behavior when compared to other cost centres. 

There does not appear to be any evidence to suggest that operators become less cautious as they become more experienced. Port Coquitlam could be a notable exception to this for experience levels that are less than 60 Months, but across the board we can see that the experience level of >60 Months has the lowest expected incidents per year for all of the cost centres.

As an operator gains more experience, the rate at which they improve also varies a lot depending on the cost centre. It is clear, for instance, that operators in Richmond do not exhibit much improvement in their expected incidents per year until they reach >60 Months of experience. On the other hand, operators in Vancouver and Burnaby appear to exhibit relatively significant improvement as they move through each experience level, as demonstrated by the non-overlapping 90% credible intervals for VTC.

<6 Months of experience largely seems like "the wild west". It would appear that nothing meaningful can be said about these operators other than that there is a very large variance in incidents per year no matter the cost centre. Burnaby is a notable exception to this, however. Indeed, Burnaby's operators with <6 Months of experience have a significantly higher expected incidents per year when compared to the overall average for all operators with <6 Months of experience.  

Finally, there is a clear difference between experienced shuttle operators and non-shuttle operators. Shuttle operators overall do not get into as many incidents per year when compared to non-shuttle operators, perhaps because they are in general easier to operate.

<center> <h4>Predictive Analysis</h4> </center>

The following interactive graph gives the actual probability of a specific operator having K incidents in a year, given that the operator has at least one incident. This differs from the above since it provides predictions not for the average incidents per year of all operators in a specific cost centre with a particular experience level, but for the actual observed number of incidents per year for any **single** operator.

Therefore, this graph can be used for predicting the number of incidents per year for any operator with a known experience level and cost centre (given that they have at least one incident). The highlighted red bar gives a "best guess" for how many incidents per year an operator will have. For instance, an operator in Vancouver with >60 Months of experience will be expected to have three incidents in a year. However, this is just a single number and indeed, the 90% credible interval gives the entire range of most likely outcomes taking into consideration uncertainty. For example, the model estimates that there is a 90% chance that an operator in Vancouver (who will have at least one incident) with >60 Months of experience will have exactly one to six incidents in a year.

```{r Operator Analysis: Plot, echo = FALSE, warning = FALSE}
selectInput("cost_centre_oa", label = "Cost Centre:", 
            choices = unique(predictor_combinations$cost_centre), selected = "VTC")
selectInput("experience_oa", label = "Experience Level:",
            choices = unique(predictor_combinations$experience), selected = ">60 Months")
 
renderPlotly({
  
  row_val <- which(input$cost_centre_oa == predictor_combinations$cost_centre & input$experience_oa == predictor_combinations$experience)
  
  median_samp <- round(median(posterior_samples[, row_val] %>% pull()), 0)
  lower <- quantile(posterior_samples[, row_val] %>% pull(), 0.05)
  upper <- quantile(posterior_samples[, row_val] %>% pull(), 0.95)
  
  plotting_data_oa <- posterior_samples[, row_val] %>%
    set_names("Number of Incidents/Yr") %>%
    mutate(`Number of Incidents/Yr` = as.character(`Number of Incidents/Yr`)) %>%
    group_by(`Number of Incidents/Yr`) %>%
    count() %>%
    ungroup() %>%
    mutate(`Probability of Occurring` = round(n / sum(n), 2))
  
  total_gte8 <- sum(plotting_data_oa$`Probability of Occurring`[plotting_data_oa$`Number of Incidents/Yr` >= 8])
  
  plotting_data_oa <- plotting_data_oa %>%
    filter(`Number of Incidents/Yr` %in% seq(1, 7, 1)) %>%
    bind_rows(tibble(`Number of Incidents/Yr` = '8+', n = NA, `Probability of Occurring` = total_gte8)) %>%
    mutate(indicator = as.factor(ifelse(`Number of Incidents/Yr` == median_samp, "Median", "No")))
  
  ggplotly(ggplot(data = plotting_data_oa, aes(x = `Number of Incidents/Yr`, y = `Probability of Occurring`, fill = indicator)) +
  geom_bar(stat = "identity") +
  labs(x = "Incidents/Year", y = "Probability of Occurring", 
       title = paste0("Experience: ", input$experience_oa, ", Cost Centre: ", input$cost_centre_oa, "<br>", "<sup>", "Best Point Prediction in Red, ", "90% Credible Interval: ", "[" , round(lower, 2), ", ", round(upper, 2), "]", "</sup>")) +
  theme_bw() +
  scale_fill_manual(breaks = c("Median"), values = c("red", "gray"), guide = FALSE) +
  theme(
      legend.position = "none",
      axis.title.y = element_text(vjust = 5),
      axis.title.x = element_text(vjust = -3)) +
  scale_x_discrete(drop = FALSE), autosize = TRUE, tooltip = c("Number of Incidents/Yr", "Probability of Occurring")) 
  
  })
```
This tool further emphasizes what was observed in the prior section. If the user switches to cost centre PTC for example, they can see that operators in Port Coquitlam with >6 Months & <18 Months of experience have a lower expected number of incidents per year when compared to operators with >18 Months & <60 Months of experience. The number of incidents per year is also much more certain for the **less experienced** operators when compared to the more experienced ones which is very counter intuitive and unique to Port Coquitlam. 

<center> <h4>Conclusions and Recommendations</h4> </center>

In the end, we have observed the following points based solely on this dataset:

- As operators become more experienced, they are expected to have fewer incidents per year overall. However, in some areas such as Port Coquitlam this is not true and the reverse occurs.
- There is little evidence to suggest that operators become complacent as they exit the probationary period (roughly <6 Months), with most cost centres displaying significant reductions in expected incidents/yr as an operator becomes more experienced.
- Port Coquitlam is a significant outlier to the above two hypotheses. Port Coquitlam operators tend to have their expected incidents per year **increase** with experience until they hit >60 Months in which they fall back in line with other cost centres. This could possibly be due to complacency, but regardless further investigation is needed as to why this is occurring.
- The speed at which operators "learn" to avoid incidents varies widely depending on the cost centre. Operators in Vancouver, Surrey, and Burnaby appear to exhibit significant improvement as they gain more experience. However, for operators in Richmond there is very little improvement for operators until they hit >60 Months of experience.
- There is little to no difference in expected incidents per year for operators with <6 Months of experience over all cost centres. However, Burnaby has a notably higher incidents per year for operators with <6 Months of experience than the overall average, and perhaps more training for new operators is needed for those who work in the Burnaby region, or perhaps these operators experience notably different situations compared to others.
- Shuttle operators clearly exhibit fewer incidents per year than non-shuttle operators, probably because shuttles are smaller and therefore easier to operate.

### A Combined Analysis of All Factors Using Machine Learning

<center> <h4>TransLink's Overall Business Question</h4> </center>

TransLink's overall goal is to identify certain variables that are highly predictive of operator incidents. Through this analysis, the hope is that certain preventable measures can be taken on identified variables of interest to help reduce insurance costs. The previous section only looked at operator experience levels and operator cost centres/locations, but this ignores multiple other factors that potentially distort the previous analysis. 

For example, while in the previous section it was observed that more experienced operators get into fewer incidents, this potentially is distorted by the fact that more experienced operators may choose to operate less busy bus lines due to seniority. Therefore, this analysis seeks to analyze everything simultaneously such that the effects of multiple other possible influencing factors are controlled for. In particular, TransLink has expressed interest in understanding the impact of weather conditions, bus characteristics, location, and time in addition to operator characteristics in order to get a better understanding of what is actually driving bus incidents.
  
<center> <h4>Overall Predictive Power of Variables in the Model</h4> </center>

We employ a machine learning model to simultaneously assess the overall predictive power of all of these various factors using a very similar methodology to what is described in two papers ([@Montreal] and [@WilsonML]). More details are described in the final written report that is also submitted with this one. On average, the model shown here correctly ranks a scenario with an actual incident to be of higher risk than a scenario with no incident, 85% of the time. This is in line with the papers in which this model is based on.

```{r ML Model: Helper, echo = FALSE, include = FALSE}

class1 <- read_csv("results/ml_model/report/class1_shap.csv") %>%
  select(-X1) 

original_train <- read_csv("results/ml_model/report/full_data.csv") %>%
  select(-X1)

filter_for_graph <- function(variable_name) {
  
  var_only <- class1 %>%
    mutate_all(.funs = function(x) exp(x) / (1 + exp(x))) %>%
    select({{variable_name}}) %>%
    rename(score = all_of(variable_name))

  graphing <- tibble(original_train %>% select({{variable_name}}), var_only[, 1]) 
  
  colnames(graphing) <- c("variable", "score")
  
  graphing
  
}

line_number_summary <- filter_for_graph("line_no") %>%
  group_by(variable) %>%
  summarize(score = median(score))

```

In answering the business question, the graph below summarizes the variables that are most important in determining the risk of an incident occurring, as estimated by the model. 

```{r ML Model: Summary Plots, echo = FALSE}

summary_plot <- class1 %>%
  mutate_all(.funs = list(abs)) %>%
  summarize_all(mean) %>%
  gather(key = "Predictor", value = "Mean Absolute Score") %>%
  mutate(Predictor = case_when(
    Predictor == "hour" ~ "Hour",
    Predictor == "day_of_week" ~ "Day Of Week",
    Predictor == "bus_age" ~ "Bus Age",
    Predictor == "bus_carry_capacity" ~ "Bus Carry Capacity",
    Predictor == "line_no" ~ "Bus Line Number",
    Predictor == "city" ~ "City",
    Predictor == "pressure" ~ "Atmospheric Pressure",
    Predictor == "rel_hum" ~ "Relative Humidity",
    Predictor == "elev" ~ "Elevation",
    Predictor == "temp" ~ "Temperature",
    Predictor == "visib" ~ "Visibility",
    Predictor == "wind_dir" ~ "Wind Direction",
    Predictor == "wind_spd" ~ "Wind Speed",
    Predictor == "total_precip" ~ "Total Precipitation",
    Predictor == "total_rain" ~ "Total Rain",
    Predictor == "total_snow" ~ "Total Snow",
    Predictor == "experience_in_months" ~ "Operator Experience in Months",
    Predictor == "is_shuttle" ~ "Shuttle Y/N",
    Predictor == "asset_class" ~ "Asset Class",
    Predictor == "asset_manufactmodel" ~ "Asset Manufacturer Model",
    Predictor == "month" ~ "Month",
    TRUE ~ Predictor
  )) %>%
  mutate(Predictor = fct_reorder(Predictor, `Mean Absolute Score`),
         `Mean Absolute Score` = round(`Mean Absolute Score`, 4)) 

ggplotly(ggplot(data = summary_plot, aes(x = Predictor, y = `Mean Absolute Score`)) +
  geom_bar(stat = 'identity', position = 'dodge') +
  coord_flip() +
  theme_bw() +
  labs(title = "Variables Most Correlated With Incidents"), width = 870)

```

The scores shown on the graph above represent the overall importance a variable has in determining whether an incident is more or less likely to occur. The larger the score, the more important a variable is.

As we can see, it is quite obvious that the bus line number is by far the most important variable in determining whether an incident is likely to occur or not. This is not too surprising considering that some bus lines naturally move through more populated areas. To test this hypothesis and many others, we can use the following tool below to actually see the estimated risk per each line. In addition, we can see how the risk changes for all of the other variables used in this model as well. 

```{r ML Model: Marginal Effects, echo = FALSE}

tabsetPanel(
  tabPanel("Time", selectInput("time_input", label = "Time Variable of Interest:", 
            choices = c("Hour", "Month", "Day of Week"), selected = "Month"), plotlyOutput("time_plot")),
  tabPanel("Bus Line Number",
           tabsetPanel(
             tabPanel("Top Lines Per Risk",
                    sliderInput("line_no_input", label = "Select Ranking of Lines to View:", value = c(1, 5), min = 1, max =        length(unique(original_train$line_no))),
                    checkboxInput("line_no_asc", label = "Lowest Risk First", value = FALSE),
                    plotlyOutput("line_plot_top")
          ),
              tabPanel("Individual Line Selector",
                     selectInput("line_no_input_ind", label = "Select Specific Lines to View:", 
                                 choices = unique(original_train$line_no), selected = "10", multiple = TRUE),
                     plotlyOutput("line_no_indiv"))
          )),
  tabPanel("Weather",
           selectInput(
             "weather_input",
             label = "Weather Variable of Interest:",
             choices = c("Temperature", "Total Rain", "Total Snow", "Total Precipitation", "Wind Direction", "Wind Speed", "Pressure", "Relative Humidity", "Elevation", "Visibility"),
             selected = "Temperature"),
           conditionalPanel(
            "input.weather_input != 'Elevation'",
           sliderInput("avg_risk_range_input",
                       label = "Average Risk in Range:",
                       min = -400, 
                       max = 400, step = 1, value = c(0, 10))),
  plotlyOutput("weather_plot")),
  tabPanel("Operator and City of Incident",
           selectInput(
             "operator_input",
             label = "Variable of Interest:",
             choices = c("Operator Experience", "City of Incident"),
             selected = "Operator Experience"),
           conditionalPanel(
             "input.operator_input == 'Operator Experience'",
             sliderInput("avg_risk_range_operator_input",
                         label = "Average Risk in Range:",
                         min = 0,
                         max = round(max(original_train$experience_in_months, na.rm = TRUE), 4),
                         value = c(0, 30), step = 1)
           ),
  plotlyOutput("operator_plot")),
  tabPanel("Bus Characteristics",
           selectInput(
             "bus_input",
             label = "Bus Variable of Interest:",
             choices = c("Asset Manufacturer Model", "Asset Class", "Shuttle/Regular Bus", "Bus Age", "Bus Carrying Capacity"),
             selected = "Shuttle/No Shuttle"),
           conditionalPanel(
             "input.bus_input == 'Bus Age'",
             sliderInput("avg_risk_range_bus_input",
                         label = "Average Risk in Range:",
                         min = 0,
                         max = max(original_train$bus_age, na.rm = TRUE),
                         value = c(0, 5), step = 1)
           ),
  plotlyOutput("bus_plot"))
)

output$time_plot <- renderPlotly({
  
  if (input$time_input == "Hour") {
    
    all_graphing <- filter_for_graph("hour") %>%
      mutate(variable = as.factor(variable),
             variable = fct_relevel(variable, as.character(0:23))) 
  
    } else if (input$time_input == "Month") {
      
    all_graphing <- filter_for_graph("month") %>%
      mutate(variable = as.character(variable)) %>%
      mutate(variable = case_when(
        variable == "1" ~ "Jan",
        variable == "2" ~ "Feb",
        variable == "3" ~ "Mar",
        variable == "4" ~ "Apr",
        variable == "5" ~ "May",
        variable == "6" ~ "Jun",
        variable == "7" ~ "Jul",
        variable == "8" ~ "Aug",
        variable == "9" ~ "Sep",
        variable == "10" ~ "Oct",
        variable == "11" ~ "Nov",
        variable == "12" ~ "Dec",
        TRUE ~ variable
      )) %>%
        mutate(variable = fct_relevel(variable, c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")))
  
    } else {
    
    all_graphing <- filter_for_graph("day_of_week") %>%
      mutate(variable = fct_relevel(variable, c("Sun", "Mon", "Tue", "Wed", "Thu", "Fri", "Sat")))
    
    }

  colnames(all_graphing) <- c(input$time_input, "Score")
  
  overall_mean <- tibble(
    `Global Average Risk` = round(mean(all_graphing$Score), 2)
  )
  
  ggplotly(ggplot(all_graphing, aes(x = !!sym(input$time_input), y = Score, group = !!sym(input$time_input))) +
    geom_boxplot() +
    geom_hline(data = overall_mean, aes(yintercept = `Global Average Risk`), color = "red", show.legend = FALSE) + 
    theme_bw() + 
    labs(
      title = paste(tools::toTitleCase(input$time_input), "Estimated Risk"),
      x = paste(tools::toTitleCase(input$time_input)),
      y = "Estimated Risk of Incident"))
  
})

output$line_plot_top <- renderPlotly({
  
  score <- exp(class1$line_no) / (1 + exp(class1$line_no))
  overall_mean <- tibble(
    `Global Average Risk` = round(mean(score), 2)
  )
  
  if (input$line_no_asc == TRUE) {
    
  lines_to_show <- line_number_summary %>%
    arrange(score) %>%
    .[input$line_no_input[1]:input$line_no_input[2], ] %>%
    select(variable) %>%
    pull()
    
  } else {
  
  lines_to_show <- line_number_summary %>%
    arrange(-score) %>%
    .[input$line_no_input[1]:input$line_no_input[2], ] %>%
    select(variable) %>%
    pull()
  
  }
  
  all_graphing <- filter_for_graph("line_no") %>%
    rename(line_no = variable) %>%
    filter(line_no %in% lines_to_show) %>%
    mutate(line_no = fct_reorder(line_no, .$score, .desc = TRUE))
  
  colnames(all_graphing) <- c("Line Number", "Score")
  
  ggplotly(ggplot(all_graphing, aes(x = `Line Number`, y = `Score`, group = `Line Number`)) +
    geom_boxplot() +
    theme_bw() +
    geom_hline(data = overall_mean, aes(yintercept = `Global Average Risk`), color = "red", show.legend = FALSE) +
    theme(axis.text.x = element_text(angle = 45)) + 
    labs(
      title = paste0("Top ", input$line_no_input, " Highest/Lowest Risk Lines"),
      x = paste(tools::toTitleCase(input$time_input)),
      y = "Estimated Risk Score"))
  
})

output$line_plot_top <- renderPlotly({
  
  score <- exp(class1$line_no) / (1 + exp(class1$line_no))
  overall_mean <- tibble(
    `Global Average Risk` = round(mean(score), 2)
  )
  
  if (input$line_no_asc == TRUE) {
    
  lines_to_show <- line_number_summary %>%
    arrange(score) %>%
    .[input$line_no_input[1]:input$line_no_input[2], ] %>%
    select(variable) %>%
    pull()
    
  } else {
  
  lines_to_show <- line_number_summary %>%
    arrange(-score) %>%
    .[input$line_no_input[1]:input$line_no_input[2], ] %>%
    select(variable) %>%
    pull()
  
  }
  
  all_graphing <- filter_for_graph("line_no") %>%
    rename(line_no = variable) %>%
    filter(line_no %in% lines_to_show) %>%
    mutate(line_no = fct_reorder(line_no, .$score, .desc = TRUE))
  
  colnames(all_graphing) <- c("Line Number", "Score")
  ggplotly(ggplot(all_graphing, aes(x = `Line Number`, y = Score, group = `Line Number`)) +
    geom_boxplot() +
    theme_bw() +
    geom_hline(data = overall_mean, aes(yintercept = `Global Average Risk`), color = "red", show.legend = FALSE) +
    theme(axis.text.x = element_text(angle = 45)) + 
    labs(
      title = paste("Top", input$line_no_input, "Highest/Lowest Risk Lines"),
      x = "Line Number",
      y = "Estimated Risk Score"))
  
})

output$line_no_indiv <- renderPlotly({
  
  validate(need(!is.null(input$line_no_input_ind), "No line number selected."))
  
  score <- exp(class1$line_no) / (1 + exp(class1$line_no))
  overall_mean <- tibble(
    `Global Average Risk` = round(mean(score), 2)
  )
  
  all_graphing <- filter_for_graph("line_no") %>%
    rename(line_no = variable) %>%
    filter(line_no %in% input$line_no_input_ind) %>%
    mutate(line_no = fct_reorder(line_no, .$score, .desc = TRUE))
  
  ggplotly(ggplot(all_graphing, aes(x = line_no, y = score, group = line_no)) +
    geom_boxplot() +
    theme_bw() +
    geom_hline(data = overall_mean, aes(yintercept = `Global Average Risk`), color = "red", show.legend = FALSE) +
    theme(axis.text.x = element_text(angle = 45)) + 
    labs(
      title = paste("Top", input$line_no_input, "Highest/Lowest Risk Lines"),
      x = "Line Number",
      y = "Estimated Risk Score"))
  
})

output$weather_plot <- renderPlotly({
  
  lookup <- tibble(
    choices = c("Temperature", "Total Rain", "Total Snow", "Total Precipitation", "Wind Direction", "Wind Speed", "Pressure", "Relative Humidity", "Elevation", "Visibility"),
    var_name = c("temp", "total_rain", "total_snow", "total_precip", "wind_dir", "wind_spd", "pressure", "rel_hum", "elev", "visib"),
    units = c("°C", "mm", "cm", "mm", "10's of degree", "km/h", "kPa", "%", "m", "km"))
  
  all_graphing <- filter_for_graph(lookup$var_name[which(lookup$choices == input$weather_input)]) 
  
  colnames(all_graphing) <- c(input$weather_input, "Score")
  
  overall_mean <- tibble(
    `Global Average Risk` = round(mean(all_graphing$Score), 2)
  )  

  if (input$weather_input == "Elevation") {
  
  all_graphing <- all_graphing %>%
    mutate(`Elevation` = as.factor(`Elevation`)) %>%
    mutate(`Elevation` = fct_relevel(`Elevation`, c("2.5", "3.1", "4.3", "5", "13", "170.2")))

  ggplotly(ggplot(all_graphing, aes(x = !!sym(input$weather_input), y = Score, group = !!sym(input$weather_input))) +
    geom_boxplot() +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 45)) + 
    geom_hline(data = overall_mean, aes(yintercept = `Global Average Risk`), color = "red", show.legend = FALSE) +
    labs(
      title = "Estimated Risk Per Elevation Level",
      x = paste0("Elevation Level ", "(", lookup$units[which(lookup$choices == input$weather_input)], ")"),
      y = "Estimated Risk Score"))
    
  } else {
  
  avg_risk_range <- class1[, lookup$var_name[which(lookup$choices == input$weather_input)]] %>%
    bind_cols(., original_train[, lookup$var_name[which(lookup$choices == input$weather_input)]]) 
  
  colnames(avg_risk_range) <- c("SHAP", "variable")
  
  avg_risk_range <- avg_risk_range %>%
    filter(variable >= input$avg_risk_range_input[1], variable <= input$avg_risk_range_input[2]) %>%
    select(SHAP) %>%
    pull() 
  
  avg_risk_range <- exp(avg_risk_range) / (1 + exp(avg_risk_range))
  
  ggplotly(ggplot(all_graphing, aes(x = !!sym(input$weather_input), y = Score)) +
    geom_smooth(method = "gam") +
    theme_bw() + 
    geom_hline(data = overall_mean, aes(yintercept = `Global Average Risk`), color = "red", show.legend = FALSE) +
    labs(
      title = paste0("Estimated Risk For Changing Values of: ", input$weather_input,
                     "<br>", "<sup>", "Estimated Average Risk in Range: [", input$avg_risk_range_input[1], ", ", input$avg_risk_range_input[2], "] ", "is: ", round(mean(avg_risk_range), 2)),
      x = paste0(input$weather_input, " ", "(", lookup$units[which(lookup$choices == input$weather_input)], ")"),
      y = "Estimated Risk Score"))
  }
})

output$operator_plot <- renderPlotly({
  
  if (input$operator_input == "City of Incident") {
  
  scores <- exp(class1$city) / (1 + exp(class1$city))  
  overall_mean <- tibble(
    `Global Average Risk` = round(mean(scores), 2)
  )
    
    all_graphing <- filter_for_graph("city") %>%
      rename("City of Incident" = variable, Score = score) %>%
      mutate(`City of Incident` = ifelse(is.na(`City of Incident`), "N/A", `City of Incident`))
    
    ggplotly(ggplot(all_graphing, aes(x = `City of Incident`, y = Score, group = `City of Incident`)) +
      geom_boxplot() +
      theme_bw() +
      theme(axis.text.x = element_text(angle = 45)) + 
      geom_hline(data = overall_mean, aes(yintercept = `Global Average Risk`), color = "red", show.legend = FALSE) +
      labs(
        title = paste("Estimated Risk Per", input$operator_input),
        x = paste(input$operator_input),
        y = "Estimated Risk Score"))
  
    } else {
    
    scores <- exp(class1$experience_in_months) / (1 + exp(class1$experience_in_months))  
    overall_mean <- tibble(
    `Global Average Risk` = round(mean(scores), 2)
    )  
      
    all_graphing <- filter_for_graph("experience_in_months") %>%
        rename("Operator Experience in Months" = variable)
    
    avg_risk_range <- class1 %>%
      select(experience_in_months) %>%
      rename(SHAP = experience_in_months) %>%
      bind_cols(., original_train %>% select(experience_in_months)) %>%
      filter(experience_in_months >= input$avg_risk_range_operator_input[1],
             experience_in_months <= input$avg_risk_range_operator_input[2]) %>%
      select(SHAP) %>%
      pull()
    
    avg_risk_range <- exp(avg_risk_range) / (1 + exp(avg_risk_range))
    
    ggplotly(ggplot(all_graphing, aes(x = `Operator Experience in Months`, y = score)) +
      geom_smooth(method = "gam") +
      theme_bw() + 
      geom_hline(data = overall_mean, aes(yintercept = `Global Average Risk`), color = "red", show.legend = FALSE) +
      labs(
        title = paste0("Estimated Risk For Changing Values of: ", input$operator_input,
                       "<br>", "<sup>", "Estimated Average Risk in Range: [", input$avg_risk_range_operator_input[1], ", ", input$avg_risk_range_operator_input[2], "] ", "is: ", round(mean(avg_risk_range), 2)),
        x = paste0(input$operator_input, " ", "(", "months", ")"),
        y = "Estimated Risk Score"))
      
  }
})

output$bus_plot <- renderPlotly({
  
  lookup <- tibble(
    choices = c("Asset Manufacturer Model", "Asset Class", "Shuttle/Regular Bus", "Bus Age", "Bus Carrying Capacity"),
    var_name = c("asset_manufactmodel", "asset_class", "is_shuttle", "bus_age", "bus_carry_capacity")
  )
  
  all_graphing <- filter_for_graph(lookup$var_name[which(lookup$choices == input$bus_input)])
  
  overall_mean <- tibble(
    `Global Average Risk` = round(mean(all_graphing$score), 2)
  )
  
  if (input$bus_input == "Bus Age") {
  
  colnames(all_graphing) <- c(input$bus_input, "Score")
  
  avg_risk_range <- class1 %>%
      select(bus_age) %>%
      rename(SHAP = bus_age) %>%
      bind_cols(., original_train %>% select(bus_age)) %>%
      filter(bus_age >= input$avg_risk_range_bus_input[1],
             bus_age <= input$avg_risk_range_bus_input[2]) %>%
      select(SHAP) %>%
      pull()
  
  avg_risk_range <- exp(avg_risk_range) / (1 + exp(avg_risk_range))
  
  ggplotly(ggplot(all_graphing, aes(x = `Bus Age`, y = Score)) +
      geom_smooth(method = "gam") +
      theme_bw() + 
      geom_hline(data = overall_mean, aes(yintercept = `Global Average Risk`), color = "red", show.legend = FALSE) +
      labs(
title = paste0("Estimated Risk For Changing Values of: ", input$bus_input,
                       "<br>", "<sup>", "Estimated Average Risk in Range: [", input$avg_risk_range_bus_input[1], ", ", input$avg_risk_range_bus_input[2], "] ", "is: ", round(mean(avg_risk_range), 2)),
        x = paste0(input$bus_input, " ", "(", "years", ")"),
        y = "Estimated Risk Score"))
    
  } else {
    
  all_graphing <- all_graphing %>%
      mutate(variable = as.character(variable))
    
    if (input$bus_input == "Bus Carrying Capacity") {
      
      all_graphing <- all_graphing %>%
        mutate(variable = if_else(is.na(variable), "N/A", variable)) %>%
        mutate(variable = fct_relevel(variable, as.character(sort(unique(original_train$bus_carry_capacity)))))
      
    } else if (input$bus_input == "Shuttle/Regular Bus") {
      
      all_graphing <- all_graphing %>%
        mutate(variable = ifelse(variable == 1, "Shuttle", "Regular"), 
               variable = fct_relevel(variable, c("Shuttle", "Regular")))
    } else {
      
      all_graphing <- all_graphing %>%
        mutate(variable = ifelse(is.na(variable), "N/A", variable),
               variable = fct_reorder(variable, .$score))
      
    }
  
  colnames(all_graphing) <- c(input$bus_input, "Score")
  
  ggplotly(ggplot(all_graphing, aes(x = !!sym(input$bus_input), y = Score, group = !!sym(input$bus_input))) +
    geom_boxplot() +
    theme_bw() +
    theme(axis.text.x = element_text(angle = 45)) + 
    geom_hline(data = overall_mean, aes(yintercept = `Global Average Risk`), color = "red", show.legend = FALSE) +
    labs(
      title = paste("Estimated Risk Per", input$bus_input),
      x = paste(input$bus_input),
      y = "Estimated Risk Score"))

  }
  
})

observeEvent(input$weather_input, {
  
  lookup <- tibble(
      choices = c("Temperature", "Total Rain", "Total Snow", "Total Precipitation", "Wind Direction", "Wind Speed", "Pressure", "Relative Humidity", "Elevation", "Visibility"),
      var_name = c("temp", "total_rain", "total_snow", "total_precip", "wind_dir", "wind_spd", "pressure", "rel_hum", "elev", "visib"),
      units = c("°C", "mm", "cm", "mm", "10's of degree", "km/h", "kPa", "%", "m", "km"))
  
  find_min <- min(original_train[, c(lookup$var_name[which(lookup$choices == input$weather_input)])], na.rm = TRUE)
  find_max <- max(original_train[, c(lookup$var_name[which(lookup$choices == input$weather_input)])], na.rm = TRUE)
  
  if (input$weather_input == "Elevation") {
    updateSliderInput(session = session, inputId = "avg_risk_range_input", min = 0, max = 0)
  } else {
    updateSliderInput(session = session, inputId = "avg_risk_range_input", min = find_min, max = find_max)
  }
})
  
  

```

Estimated risk scores shown above are adjusted to be between zero and one and describe the likelihood of an incident occurring for a given scenario. A risk score of one means that it is very likely an incident will occur - a risk score closer to zero means it is quite unlikely. The red horizontal line shown above in each plot) is the average risk over all values of the variable being viewed - this can be interpreted as unity risk or "no effect". In addition, just like the operators analysis it should be stressed that these are estimated **average** risk scores for a **group of observations** with the same characteristics and not the actual predicted risk scores for a single, specific scenario (see the next section if this is desired).

It is important to stress that these risk scores are **not** probabilities of an incident occurring under a specific scenario. Indeed, some of these scores have values as high as 0.75 which cannot realistically be the probability of an incident occurring under any scenario (incidents are much rarer than that). The reason for why we cannot interpret these scores as probabilities is related to how this model is actually created, but regardless, these scores can only be interpreted as relative measures. That is, these scores have no meaning by themselves but do have proper meaning in relation to each other.

As an example, we see that line 22 is estimated to have the highest risk out of all bus lines with a median score of 0.68, holding all other variables constant. Similarly, the new R4 bus line is estimated to have a median risk score of 0.57. None of these scores have any meaning by themselves, but we can make the conclusions that:

1) Line 22 is roughly 0.68/0.57 = 1.20 times (20%) more likely to be involved in an incident than the R4
2) Both lines are above the overall average of 0.5 risk

The boxplots can be used to gauge how uncertain the overall estimates are, but the medians can be considered our best point estimates. These stats can be viewed by hovering the mouse cursor over specific boxes directly on the plot.

If the variable being analyzed can be any arbitrary number (like all of the weather variables except for elevation) then a plot displaying the estimated "risk curve" for that variable is shown. This gives the estimated average risk for any value of the variable, holding all other variables in the model constant. For some of these plots, the user may notice grey regions for some extreme values of the variable being viewed, such as for very low temperatures. These grey regions reflect the uncertainty in the estimated risk curve in which the curve realistically could fall anywhere in the region. These grey regions are only noticeable for very extreme values of the variable being analyzed since there is very little (if any) data to estimate the effect for these values (such as -15°C which almost never occurs in the Greater Vancouver area). Finally, these plots with risk curves also have an additional slider that allows the user to calculate the estimated average risk for a specific range of the variable being viewed. The user just has to move the slider input to the range they are interested in, and then the calculated average risk for the selected range is displayed in the subtitle of the plot.

<center> <h4>Results</h4> </center>

Below, we highlight some key observations from the tool above.

- __*Lines*__:
  
Overall, we can see that the lines estimated to be of highest risk for an incident are the 22, 10, 41, 20, 14 and the 4. All of these lines with the exception of line 41 go through Downtown Vancouver. It is difficult to know exactly why Downtown is such a troublesome area - perhaps more traffic and overall population density could play a role. Indeed, we see in the spatial analysis section that Downtown Vancouver dominates the total number of claims as well. 

Line 41 is the bus line that sticks out quite noticeably from the others in that it is the only line out of the top six that does not actually go to Downtown Vancouver. However, this bus line does cover a very large distance which dramatically increases the amount of exposure this particular line has. In general, the riskiest lines are those that stretch large portions of Metro Vancouver. One notable exception to this is line 5 which covers a fairly small distance but in a very dense area (Robson Square). 

Avoiding the most dense areas of Vancouver in some fashion, perhaps by modifying routes to avoid high traffic areas could possibly be an avenue of interest. Knowing which specific roads are of particularly high risk is the next step in this analysis that would help enable TransLink to design safer routes. This is more challenging but entirely possible, largely using the same methodology employed in this report.

The safest bus lines all are outside of Metro Vancouver for the most part (640, 104, 562, 119, 103) - all are estimated to have a risk score of around 0.05. Thus, these lines are all ten times less likely to be involved in an incident when compared to the global average and roughly 14 times less likely to be involved in an incident than the worst offending lines.

- __*Hour*__:

There are some very interesting results from this analysis regarding the hour of the day. As one might expect, the riskiest times during the day are between 7 am and 6 pm, with 3-5 pm having the highest likelihood of an incident likely due to traffic congestion. Finally, the model estimates that the afternoon (especially around 3-5 pm) is 1.1 times more likely to be involved in an incident when compared to that of the morning rush hour (7 am to 9 am).

There is one very strange time that is a clear outlier when compared to others - 3 am. For some strange reason, 3 am is estimated to be of higher risk when compared to other off-peak times which is very bizarre in general (though it is still below average). In fact, an incident is roughly two times more likely to occur in the 3 am hour than 12 am and is comparable in risk to that of 10 pm. This is very strange behavior and is worth exploring further as to why this time is suspiciously higher than other off-peak times.  

- __*Month*__:

Month is the second most predictive variable in the model, and using the tool above it is easy to see why. There is a clear lower risk of incidence in March, June, July, and September when compared to all of the other months. However, we suspect that the differences between the months may not be for the same reasons. January and February could be explained possibly by the erratic weather typically observed in these months. In April and May, this could be the result of larger amounts of rain due to the spring season. 

It may be easier to deduce why June and July are lower incident months - indeed, there is likely less traffic congestion and bus activity due to the Summer season. 

Interestingly, October, November, and December are also estimated as high risk months. These are the "holiday months" in which TransLink actually offers lower service hours. One would think that this would result in fewer incidents but the opposite occurs. 

- __*Weather*__:

Elevation is noted to be of high predictive power but we believe this is merely a proxy for the city of incident (which from the prior analysis, we saw is predictive of an incident occurring). The tool above shows this - the risk for most of the elevations is the same except at 2.5 meters which corresponds to a weather station located on the Vancouver Sea Island near the airport. We believe that this variable is therefore being used as a proxy that compares Vancouver vs. Richmond/Delta.

Two notable variables are that of atmospheric pressure and temperature, both of which are noted to be predictive of an incident. When we view the risk curve for pressure, we see that lower pressures have higher risk which intuitively makes a lot of sense (lower pressures often yields more precipitation, making driving conditions more difficult). However, there is a slight spike at pressures around 103 kPa in which the risk suddenly is driven up again. Higher pressures often yield cloudless skies and a potential explanation for the increase risk could be related to increased congestion and pedestrians on "nice" days. The temperature risk curve seems to potentially support this idea - again we see a decreasing risk curve overall as temperature increases until about 31°C in which the risk suddenly starts increasing.

For the risk curve regarding the amount of rain, it would appear that rain amounts < 10 mm have very little effect on estimated risk (in fact, the model estimates a slightly lower than average risk of an incident for rain amounts < 5 mm). Once rain increases beyond 10 mm, however, we see that the risk starts increasing in a rather expected way. Rain amounts around 20 mm are particularly noteworthy in which an incident is about 1.1 times more likely to occur when it rains around 20 mm when compared to scenarios with no rain.

We do not discuss the other weather variables here since they were not found to be very predictive of incidents (and often yield relationships that are nonsensical and spurious at best).

- __*Bus Characteristics*__:

Both bus age and bus carrying capacity are noted to be highly predictive of incidents. Indeed, using the tool above we can see that bus carrying capacity is really acting as a proxy for shuttles - buses that aren't shuttles basically have the exact same risk of incidence regardless of carrying capacity and are roughly 1.3 times (0.52/0.4) more likely to occur in an incident than a shuttle.

The risk curve for bus age is very interesting. Buses less than 1 year old are estimated to be of lower risk than average, and buses in the range of [2, 20] years of age exhibit a slightly above average risk score of 0.52. However, once buses age past 24 years we see a very clear (and very certain) trend in which the estimated risk of incidence starts increasing dramatically. Indeed, a very old bus that is around 26 to 27 years old is estimated to be 1.30 times more likely to be in an incident when compared to a bus that is brand new. Therefore, replacing older buses (perhaps those in excess of 24 years) may be a relatively easy actionable item that TransLink can do to reduce the likelihood of an incident occurring.

We do not discuss the other bus characteristic variables like asset manufacturer model or asset model year since they were found to be of low importance. In the case of asset class, the variable is completely ignored by the final fitted model which suggests that there is no information at all that is useful for assessing the risk of an incident occurring.

- __*Operator Experience Revisited*__:

In the previous section, we observed that operators with more experience tend to get into fewer incidents. However, as the tool above shows, the opposite effect is observed here. Those with more experience appear to get into more incidents, and around 65 months (or about five and a half years) appears to be the point at which operators start to see elevated risk levels above the average. While this appears to be a contradiction, it should be noted that operator experience overall has limited importance after accounting for all of the other variables such as line number, weather, and time. It would seem that operator experience, after accounting for a bunch of other different variables, does not play as significant of a role as initially thought.

Overall, because this analysis actually controls for many more factors it is likely much more accurate than the previous analysis that looked at only operator characteristics. 

<center> <h4>Predicted Risk for Any Specific Scenario</h4> </center>
Finally, the following tool allows the user to query the final predicted model to get the predicted risk for any specific scenario they wish. These are not average effects over all observations in the data like in the previous section but for any **single**, future scenario. Note for brevity that we let the user change variables that are 1) important to the overall prediction and 2) easily accessible. All other variables that the user cannot change are kept constant. 

It should be noted that the quality of the risk assessment given here is completely dependent on the quality of weather forecasts provided to the model (if any). If the weather forecast is completely off, then the risk assessment will of course be inaccurate as a consequence.

```{r Predicted Risk: Combination of Variables, echo = FALSE}

source_python("doc/interactive-report/predict.py")

sidebarLayout(
  sidebarPanel(style = "overflow-y:scroll; max-height: 600px; position:relative;",
  selectInput("bus_line_custom", label = "Bus Line:", choices = unique(original_train$line_no), selected = "10"),
  sliderInput("hour_custom", label = "Hour:", min = 0, max = 23, value = 17, step = 1),
  selectInput("day_of_week_custom", label = "Day Of Week:", choices = c("Sun", "Mon", "Tue", "Wed", "Thu", "Fri", "Sat"), selected = "Fri"),
  selectInput("month_custom", label = "Month:", choices = c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"), selected = "Jan"),
  selectInput("bus_carry_capacity_custom", label = "Bus Carry Capacity:", choices = unique(original_train$bus_carry_capacity), selected = 120),
  sliderInput("bus_age_custom", label = "Bus Age (years):", min = 0, max = 30, value = 0, step = 1),
  selectInput("city_custom", label = "City:", choices = unique(original_train$city), selected = "Vancouver"),
  sliderInput("temp_custom", label = "Temperature (°C):", min = -30, max = 50, value = 10, step = 0.5),
  sliderInput("pressure_custom", label = "Atmospheric Pressure (kPa):", min = 90, max = 130, value = 102.5, step = 0.1),
  sliderInput("rain_custom", label = "Total Rain (mm):", min = 0, max = 300, value = 0, step = 0.5)),
  mainPanel(
    renderPlotly({
      
      lookup <- tibble(
        month_num = 1:12,
        month_name = c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")
      )
      
      # There should be no city. The city should autoomatically be inferred from bus line.
      # Or the city selection should change per bus line so that the user can't select illegitimate options
      shap_scores <- get_new_prediction(
        bus_line = input$bus_line_custom,
        hour = input$hour_custom,
        day = input$day_of_week_custom,
        month = lookup$month_num[which(lookup$month_name == input$month_custom)],
        bus_age = input$bus_age_custom,
        bus_carrying_cap = na.omit(input$bus_carry_capacity_custom),
        city = input$city_custom,
        temp = input$temp_custom,
        pressure = input$pressure_custom,
        total_rain = input$rain_custom
        )
      
      graphing <- as_tibble(shap_scores$shap, .name_repair = "unique") 
      colnames(graphing) <- shap_scores$column_names
      
      graphing <- graphing %>%
        select(line_no, hour, day_of_week, month, bus_carry_capacity, bus_age, city, temp, pressure, total_rain) %>%
        gather(key = "Predictor", value = "Score") %>%
        mutate(Score = round(Score, 4)) %>%
        mutate(
          Predictor = case_when(
          Predictor == "hour" ~ "Hour",
          Predictor == "day_of_week" ~ "Day Of Week",
          Predictor == "bus_carry_capacity" ~ "Bus Carry Capacity",
          Predictor == "bus_age" ~ "Bus Age",
          Predictor == "line_no" ~ "Bus Line Number",
          Predictor == "city" ~ "City",
          Predictor == "pressure" ~ "Atmospheric Pressure",
          Predictor == "temp" ~ "Temperature",
          Predictor == "total_rain" ~ "Total Rain",
          Predictor == "experience_in_months" ~ "Operator Experience in Months",
          Predictor == "month" ~ "Month",
          TRUE ~ Predictor
     )) %>%
        mutate(`Risk Direction` = ifelse(Score < 0, "Induces Lower Risk", "Induces Higher Risk")) %>%
        mutate(Predictor = fct_reorder(Predictor, abs(.$Score)))
      
      ggplotly(ggplot(graphing, aes(x = Predictor, y = Score, fill = `Risk Direction`)) +
        geom_bar(stat = "identity") +
        theme_bw() + 
        coord_flip() +
        labs(title = paste0("Risk Breakdown Per Chosen Variables", "<br>", "<sup>", "Predicted Overall Risk: ", round(shap_scores$predicted[2], 3), "</sup>")) +
        scale_fill_manual(values = c(`Induces Higher Risk` = "firebrick1", `Induces Lower Risk` = "steelblue4")), 
        tooltip = c("Predictor", "Score"), height = 600, width = 700)
      
      
    })
  )
)

observeEvent(input$bus_line_custom, {
  
        find_cities_per_line <- original_train %>%
          filter(line_no == input$bus_line_custom) %>%
          select(city) %>%
          pull() %>%
          unique(.)
        
        updateSelectInput(session = session, inputId = "city_custom", choices = find_cities_per_line)
})


```

Like in previous graphs, the scores on the x-axis provide the overall impact of the variable on the final predicted risk of incident. If the variable contributes a lot, then the bar will be larger in value. Final predicted risk scores (with the exact same interpretation as in the previous section) are displayed in the subtitle of the graph.

The direction of influence a variable has on the final prediction is indicated by the colours of the bars. A blue bar indicates that the variable is reducing the overall predicted risk score. A red bar indicates that the variable is increasing the overall predicted risk score.

The tool can also be used to further assess the effect of possible interventions on overall predicted risk. For example, the user can see how much risk will be mitigated by using newer buses. Simulations can also be performed if the user knows what the weather will be like in the future, to potentially warn drivers ahead of time to take extra precaution once certain thresholds of risk are met (especially those who are operating lines that are of high risk).

<center> <h4>Conclusions and Recommendations</h4> </center>

We summarize the key points of this entire analysis:

- Bus line is by far the most important variable in determining how likely an incident is to occur for any scenario.
- The bus lines that path specifically through Downtown Vancouver, with the exception of bus line 41, are the lines that have the highest risk of incidence. As a result, a large amount of risk can be mitigated simply by focusing on improving safety measures for all lines that move through Downtown Vancouver.
- We do not really know what are the actual causal factors that are leading to more incidents in Downtown Vancouver, but we feel that it is reasonable to think that this is a combination of greater traffic density, more pedestrians, and large amounts of acceleration/deceleration due to a larger frequency of bus stops in a relatively small area.
- As a result of the above three points, increasing training for all operators who commonly work bus lines in Downtown Vancouver (and focusing most safety improvements on Downtown Vancouver in general), is likely to yield the largest impact for TransLink in reducing incidents and therefore insurance costs.
- The approach used in this analysis can be extended to more granular levels, in particular to assess specific roads. We feel that TransLink can possibly extend this analysis to assess the risk per road (rather than per line) to potentially plan routes that avoid high risk areas.
- The months of June, July, and September are roughly 1.5 times less likely to have an incident than all other months. Lower risk in June and July is possibly the result of lower ridership and traffic congestion (due to the Summer holidays) but it is not clear as to why September is noticeably safer when compared to the others.
- 7 am and 6 pm are the times that are most risky for incidents, however, there are clear intervals within this range that are relatively safer. For example, the morning rush hour (7 am to 9 am) is roughly 1.1 times less likely to have an incident when compared to 3 pm to 5 pm. 
- There is a very suspicious peak at 3 am in which the risk suddenly increases at this time (albeit, still below average) for unknown reasons.
- As seen previously, shuttles are roughly 1.3 times less likely of an incident when compared to non-shuttles. Furthermore, there is virtually no difference in risk among smaller and fuller sized regular buses.
- Bus age is surprisingly **very** predictive of incidents. Specifically, buses that are >= 24 years of age see an increasing risk of an incident (about 1.3 times more) than buses that are relatively new (0 to 1 year old). We estimate that replacing buses in excess of 24 years of age as much as possible, or decommissioning buses earlier (such as before 24 years) can help mitigate the risk of an incident by around 22%, holding all other factors constant.
- Weather - specifically temperature and atmospheric pressure are both predictive of incidents. As the temperature increases, in general the risk of an incident decreases, however, after 30°C the risk of incident suddenly starts increasing again. A similar relationship holds for atmospheric pressure in which <100 kPA pressures in general exhibit a higher risk of incidence (due to likely more rain). At around 103-104 kPA, however, there is a noticeable bump in risk. A possible theory for this could be the result of nicer days leading to more ridership and traffic congestion. 
- Regardless, if temperatures are expected to be higher than 30°C or > 10 mm of precipitation is expected, warnings to operators to act more cautiously due to elevated risk of incidence could be a potential action TransLink could implement.

### Common Types of Claims by Location

Different locations in the Greater Vancouver area have different geographies, planning structures (including houses and buildings), and roads, all of which could influence the kinds of bus incidents and resulting claims that end of occurring. Thus, the uniqueness of each area motivates us to see if there is any pattern between the types of claims (using a dataset containing manually written claim descriptions) that are reported and specific locations. Such results can be leveraged by TransLink to better understand the types of claims that are most frequently occurring, in hopes that preventable measures specific to each location can be implemented. 
<center> <h4>Example Claim Descriptions</h4> </center>

The dashboard below analyzes the manually written claim descriptions filled out by TransLink employees. The following table displays five randomly selected claim descriptions:

- "T/P REAR ENDED STOPPED BUS"                                        
- "LEFT TURNING TP RF CORNER HIT STATIONARY BUS LS"                   
- "BUS/BUS-2257 TROLLEY POLES CONTACTED STATIONARY 2220 TROLLEY ROPE" 
- "INTOX U/K MALE FELL WHILE ALIGHTING WITH WALKER"                   
- "IRATE PASS KICKED REAR DOOR GLASS" 

The descriptions in general always describe the object hit (if any) and some kind of action associated with the claim itself (such as "fell" or "hit"). However, as we can see, claim descriptions are quite varied and messy. Therefore, we clean these descriptions to a format more suitable for analysis and in addition, we make use of natural language processing to assign part of speech tags to each word in each description.   

<center> <h4>Explanation of the Dashboard</h4> </center>

This dashboard is designed for the user to see which objects were impacted in an incident, as well as the action that took place in that incident. The dataset used to create this dashboard combines the claim description, as well as the latitudes and longitudes of the locations where each incident took place. The asset manufacturer, date of the incident and bus number are also provided.

The dashboard includes two tabs. The first tab gives information about the objects impacted in the incident. Each dot on the map of Greater Vancouver corresponds to a particular location where an incident took place, and the colour of each dot corresponds to a different object which was impacted in that incident.

The word cloud dynamically updates to display what objects were impacted in the incidents according to what is viewable on the map. In addition, the colour of the words in the word cloud correspond to the coloured dots on the map to show which objects were impacted at which locations. Finally, the size of each word in the word cloud corresponds to how frequently hit an object is according to the map view.

Five among the most frequently impacted objects are viewable in the drop down. Users can select any object from the drop down to view the locations specific to that particular object, and if they do, the map below the drop down will narrow down the locations specific to the selected impacted object. 

The second page shows the most frequent actions as described in the claim descriptions. It is similar to the first tab, and shows a map of Greater Vancouver with different colours corresponding to different actions associated with particular incidents. As before, the user can choose one of the most frequently occurring actions from the drop down to see which locations are associated with a particular action.

```{r include=FALSE}
location_data <-
    read_excel("results/claim_analysis/report/claim_colour_df.xlsx")
verb_data <-
  read_excel("results/claim_analysis/report/verb_colour_df.xlsx")
#options(spinner.color="#0275D8", spinner.color.background="#ffffff", spinner.size=10)
```


```{r include= FALSE}
ui <- dashboardPage(
  dashboardHeader(title = "Reasons for Incidents" , titleWidth = 450),
  dashboardSidebar(sidebarMenu(
    menuItem(
      "Impacted Objects",
      tabName = "dashboard",
      icon = icon("bus-alt")
    ),
    menuItem(
      "Impact Actions",
      icon = icon("car-crash"),
      tabName = "widgets",
      badgeColor = "green"
    )
  )),
  dashboardBody(tabItems(
    tabItem(
      tabName = "dashboard",
      fluidRow(box(
        leafletOutput("mymap", height = 500) %>% withSpinner(color =  "skyblue", size=2),
        status = "primary",
        width = 12,
        height = 500
      ),),
      fluidRow(
        box(
          plotOutput("plot", height = 250) %>% withSpinner(color = "skyblue", size = 2),
          title = "OBJECTS",
          status = "primary",
          width = 6
        ),
        box(
          uiOutput("frequent_impacts", height = 250) %>% withSpinner(color = "skyblue", size = 2),
          status = "primary",
          width = 6
        )
        
      ),
      
      fluidRow(
        box(
          leafletOutput("my_updated_map", height = 500) %>% withSpinner(color = "skyblue", size = 2),
          status = "primary",
          width = 12,
          height = 500
        ))
      
    ),
    
    tabItem(tabName = "widgets",
            fluidRow(
              box(
                leafletOutput("my_verb_map", height = 500) %>% withSpinner(color = "skyblue", size = 2),
                width = 12,
                height = 500
              )
              
            ),
            fluidRow(
              box(
                plotOutput("plot_verb", height = 250)%>% withSpinner(color =  "skyblue", size=2),
                title = "ACTIONS",
                width = 6
              ),
              box(uiOutput("frequent_actions") %>% withSpinner(color = "skyblue", size = 2), width = 6)
            ),
            
            fluidRow(
              box(
                leafletOutput("my_updated_verb_map", height = 500) %>% withSpinner(color = "skyblue", size = 2),
                width = 12,
                height = 500
                
              )
              
            ))
  ))
)
server <- function(input, output) {
  # leaflet map for Impacts
  output$mymap <- renderLeaflet({
    leaflet() %>%
      addProviderTiles("CartoDB.Positron") %>%
      setView(lng = -123.1171,
              lat = 49.2820,
              zoom = 12) %>%
      addCircleMarkers(
        lng = location_data$long,
        lat = location_data$latt,
        radius = 4,
        fillOpacity = 1,
        color = location_data$impact_colour,
        popup =
          paste0(
            "<b>",
            "Description",
            "</b> ",
            location_data$Description,
            "</b> <br>",
            "<b>",
            "Date: ",
            "</b> ",
            location_data$loss_date_x,
            "<br>",
            "<b>",
            "Bus Number: ",
            "</b> ",
            location_data$bus_no_x,
            "<br>",
            "<b>",
            "Manufacturer: ",
            "</b> ",
            location_data$asset_manufacturer,
            "<br>"
          )
      )
  })
  
  # leaflet map for Verbs
  output$my_verb_map <- renderLeaflet({
    leaflet() %>%
      addProviderTiles("CartoDB.Positron") %>%
      setView(lng = -123.1171,
              lat = 49.2820,
              zoom = 12) %>%
      addCircleMarkers(
        lng = verb_data$long,
        lat = verb_data$latt,
        radius = 4,
        fillOpacity = 1,
        color = verb_data$verb_colour,
        popup = paste0(
          "<b>",
          "Description",
          "</b> ",
          location_data$Description,
          "</b> <br>",
          "<b>",
          "Date: ",
          "</b> ",
          location_data$loss_date_x,
          "<br>",
          "<b>",
          "Bus Number: ",
          "</b> ",
          location_data$bus_no_x,
          "<br>",
          "<b>",
          "Manufacturer: ",
          "</b> ",
          location_data$asset_manufacturer,
          "<br>"
        )
      )
  })
  
  # wordcloud for Impacts
  
  output$plot = renderPlot({
    if (isTruthy(input$mymap_bounds)) {
      bounds = input$mymap_bounds
      df <- location_data %>% filter(
        between(long, bounds$west, bounds$east),
        between(latt, bounds$south, bounds$north)
      )
      
      wc_df_impact <- df %>% select(impact, impact_colour)
      impact_df <- count(wc_df_impact, impact, impact_colour)
      #view(impact_df)
      
      ggplot(impact_df,
             aes(
               label = impact,
               size = n,
               color = as.character(impact_colour)
             )) +
        geom_text_wordcloud_area() +
        scale_colour_identity() +
        scale_size_area(max_size = 24) +
        theme_minimal()
      
      
      
    } else
      
      ggplot(impact_df,
             aes(
               label = impact,
               size = n,
               color = as.character(impact_colour)
               
             )) +
      geom_text_wordcloud_area() +
      scale_colour_identity() +
      scale_size_area(max_size = 24) +
      theme_minimal()
  })
  
  dataInput <- reactive(if (isTruthy(input$my_verb_map_bounds)) {
    bounds = input$my_verb_map_bounds
    verb_data %>% filter(
      between(long, bounds$west, bounds$east),
      between(latt, bounds$south, bounds$north)
    )
  })
  
  # wordcloud for Verbs
  output$plot_verb = renderPlot({
    if (isTruthy(input$my_verb_map_bounds)) {
      bounds = input$my_verb_map_bounds
      df <- verb_data %>% filter(
        between(long, bounds$west, bounds$east),
        between(latt, bounds$south, bounds$north)
      )
      
      
      wc_verb_df = dataInput() %>% select(chosen_verb_x, verb_colour)
     
      verb_df <- count(wc_verb_df, chosen_verb_x, verb_colour)
      ggplot(verb_df,
             aes(
               label = chosen_verb_x,
               size = n,
               color = as.character(verb_colour)
               
             )) +
        geom_text_wordcloud_area() +
        scale_colour_identity() +
        scale_size_area(max_size = 24) +
        theme_minimal()
      
      
    } else
      
      
      verb_df <- count(wc_verb_df, chosen_verb_x, verb_colour)
    ggplot(verb_df,
           aes(
             label = chosen_verb_x,
             size = n,
             color = as.character(verb_colour)
             
           )) +
      geom_text_wordcloud_area() +
      scale_colour_identity() +
      scale_size_area(max_size = 24) +
      theme_minimal()
    
  })
  
  
  # changing the map according to selected impacts
  dat <- reactive({
    selected_impact <- input$frequent_impacts
    if (isTruthy(input$mymap_bounds)) {
      bounds = input$mymap_bounds
      df <- location_data %>% filter(
        between(long, bounds$west, bounds$east),
        between(latt, bounds$south, bounds$north)
      )
    }
    
    df %>% filter(df$impact == selected_impact)
  })
  
  # changing the map according to selected verbs
  
  dat_verb <- reactive({
    selected_verb <- input$frequent_actions
    if (isTruthy(input$my_verb_map_bounds)) {
      bounds = input$my_verb_map_bounds
      df <- verb_data %>% filter(
        between(long, bounds$west, bounds$east),
        between(latt, bounds$south, bounds$north)
      )
    }

    df %>% filter(df$chosen_verb_x == selected_verb)
  })

  # Updating the new maps with selected impacts
  
  output$my_updated_map <- renderLeaflet({
    leaflet("my_updated_map", data = dat()) %>%
      addProviderTiles("CartoDB.Positron") %>%
      addCircleMarkers(
        lng = dat()$long,
        lat = dat()$latt,
        radius = 4,
        fillOpacity = 1,
        color = dat()$impact_colour,
        popup = paste0(
          "<b>",
          "Description",
          "</b> ",
          location_data$Description,
          "</b> <br>",
          "<b>",
          "Date: ",
          "</b> ",
          location_data$loss_date_x,
          "<br>",
          "<b>",
          "Bus Number: ",
          "</b> ",
          location_data$bus_no_x,
          "<br>",
          "<b>",
          "Manufacturer: ",
          "</b> ",
          location_data$asset_manufacturer,
          "<br>"
        )
      )
    
  })
  
  # Updating the new maps with selected verbs
  
  output$my_updated_verb_map <- renderLeaflet({
    leaflet("my_updated_verb_map", data = dat_verb()) %>%
      addProviderTiles("CartoDB.Positron") %>%
      addCircleMarkers(
        lng = dat_verb()$long,
        lat = dat_verb()$latt,
        radius = 4,
        fillOpacity = 1,
        color = dat_verb()$verb_colour,
        popup = paste0(
          "<b>",
          "Description",
          "</b> ",
          location_data$Description,
          "</b> <br>",
          "<b>",
          "Date: ",
          "</b> ",
          location_data$loss_date_x,
          "<br>",
          "<b>",
          "Bus Number: ",
          "</b> ",
          location_data$bus_no_x,
          "<br>",
          "<b>",
          "Manufacturer: ",
          "</b> ",
          location_data$asset_manufacturer,
          "<br>"
        )
      )
    
  })
  
  # dropdown for Impacts
  output$frequent_impacts <- renderUI({
    if (isTruthy(input$mymap_bounds)) {
      bounds = input$mymap_bounds
      df <- location_data %>% filter(
        between(long, bounds$west, bounds$east),
        between(latt, bounds$south, bounds$north)
      )
      view(df)
      wc_df_impact <- df %>% select(impact, impact_colour)
      impact_df <- count(wc_df_impact, impact, impact_colour)
      sorted_df <- impact_df[order(-impact_df$n),]
      
      
    }
    
    selectInput(
      "frequent_impacts",
      "Most frequently Impacted objects:",
      as.character(sorted_df$impact)[1:5]
    )
  })
  
  # dropdown for verbs
  output$frequent_actions <- renderUI({
    if (isTruthy(input$my_verb_map_bounds)) {
      bounds = input$my_verb_map_bounds
      df <- verb_data %>% filter(
        between(long, bounds$west, bounds$east),
        between(latt, bounds$south, bounds$north)
      )
      view(df)
      wc_verb_df = dataInput() %>% select(chosen_verb_x, verb_colour)
      verb_df <- count(wc_verb_df, chosen_verb_x, verb_colour)
      sorted_verb_df <- verb_df[order(-verb_df$n),]
      
      
    }
    
    selectInput(
      "frequent_actions",
      "Most frequent Actions:",
      as.character(sorted_verb_df$chosen_verb_x)[1:5]
    )
  })

  
}
```

```{r , echo = FALSE}
shinyApp(ui = ui, server = server)
```

  
### Assessment of Claims Costs by Location
  
One of the primary concerns for TransLink are soaring insurance costs in recent years. As a result of these rising costs, TransLink expressed interest in a potential causal or exploratory analysis to figure out what variables actually cause bus incidents, as well as claim cost forecasts for upcoming months. However, after analyzing the available datasets, we observed that almost half of the claims are still open and in addition, there were no negative examples in which the bus completed its route without any incidents (and hence, without any cost). Thus, a predictive machine learning model on the claim costs would be potentially highly biased since open claims naturally have their final costs understated. Therefore, we opt for the use of exploratory data analysis techniques instead and developed an interactive map to easily check and explore the claim costs associated with a particular incident (if they exist). 
  
There are many variables from different datasets that might have an impact on the cost of claims per incident. Thus, as a first step in our analysis, we have built an extended dataset by joining the `2020 Collisions- Preventable and Non Preventable UBC Set Without Claim Number.csv`, `employee_experience_V2.csv` and the `claim_vehicle_employee_line.csv` datasets to get more context about each claim. In addition, we found the coordinates of each incident by using the Google Maps GeoCoding API in order to visualize them on the map. Finally, we also used the R package `leaflet` to add interactivity on the map and `shiny` to add control elements to this dashboard.

```{r, echo = FALSE}
img <- readPNG("results/processed_data/joining_datasets.png")
grid.raster(img)
```

To provide a better user experience, we first classified each incident into four levels based on their claim cost to use as an indicator of how severe a particular incident is. Then, we used the *experience level of the operators* as a first-level filter element in our interactive dashboard since this is noted as one of the more important variables that influence the number of incidents according to the operators analysis. The loss year related to each claim is also included as a filter.

The primary element in the dashboard is the interactive map in the middle, which contains all reported incidents in the city map as a point, each colored differently to indicate which cost level they belong to. In addition to the map, we also provide summary information related to each incident for additional context. To achieve good coverage, we have used a combination of: 

- Data tables; to show the number of incidents by city and the total claim costs for these incidents by bus line and bus manufacturer,
    
- a density plot; to show how bus ages are distributed for each incident,
    
- a line chart; to show how the number of incidents change over time,
    
- a histogram; to show the distribution of the number of incidents per each cost level.

$~$
  
```{r include=FALSE}
my_data <- read_csv("results/processed_data/collision_locations_with_coordinates.csv")
my_data$years <- year(my_data$loss_date)
my_data <- my_data %>% mutate(apta_desc = ifelse(apta_desc == "Collisions With Other Vehicles (At G/C)", "Collisions With Other Vehicles", 
                                                 ifelse(apta_desc == "Collisions With Objects (At G/C)", "Collisions With Objects",  apta_desc)))
my_data$bus_age <- my_data$years - my_data$asset_vehicle_year
my_data$cost_range <- cut(my_data$`paid_cost$`, breaks = c(-Inf, 200, 1000, 10000, Inf),
                          labels=c("Level1 (<$200)","Level2 ($200-$1,000)","Level3 ($1,000-$10,000)", "Level4 (>$10,000)")) 
```


```{r include= FALSE}
ui2 <-  fluidPage(
  
  sidebarLayout(
    sidebarPanel(
      sliderInput("year", "Years", min(my_data$years), max(my_data$years),
                  value = range(my_data$years), step= 1, sep = ""),
      selectInput("experience", "Experience level of the operators",
                  choices = unique(na.omit(my_data$experience_levels))),
      htmlOutput("summary"),
      tableOutput("table3"),
      tableOutput("table1"),
      tableOutput("table2")
      
    ),
    mainPanel(
      fluidRow(column(4, plotOutput("plot1", width = "100%", height = "200px") ),
               column(4, plotOutput("plot3", width = "100%", height = "200px") ),
               column(4, plotOutput("plot2", width = "100%", height = "200px") ) ),
      
      
      br(),
      leafletOutput("map")
    ), 
  ))

server2 <- function (input, output) {
  
  year_data <- reactive({
    my_data %>% filter(years > input$year[1] & years < input$year[2])
  })
  
  output$map <- renderLeaflet({
    year_data() %>% 
      leaflet()  %>%
      addProviderTiles("CartoDB.Positron", group = "Streets") %>% 
      addProviderTiles("Esri.WorldImagery", group = "Detailed") %>% 
      addProviderTiles("CartoDB.DarkMatter", group = "Dark")   %>%
      setView(lng = -123.1171, lat = 49.2820, zoom = 12)
    
  })
  
  
  
  observe({
    
    experience <- input$experience
    pal <- colorFactor(palette = c("turquoise2", "steelblue4","sienna1", "violetred1" ), levels = c("Level1 (<$200)", "Level2 ($200-$1,000)", "Level3 ($1,000-$10,000)", "Level4 (>$10,000)"))
    
    sub_data <- year_data() %>% 
      filter(year_data()$experience_levels == experience)
    
    leafletProxy("map") %>% clearControls() %>% clearMarkers()%>%
      addCircleMarkers(lng = jitter(sub_data$long, factor = 0.1),
                       lat = jitter(sub_data$lat, factor = 0.1),
                       #stroke = FALSE, fillOpacity = 0.5, radius = 3,
                       color = pal(sub_data$cost_range),
                       #clusterOptions = markerClusterOptions(maxClusterRadius = 1),
                       radius=3, # Total count
                       stroke=FALSE, # Circle stroke
                       fillOpacity=0.5,
                       popup=paste0("<b>", sub_data$apta_desc, "</b> <br>",
                                    "<b>", "Date: ", "</b> ", sub_data$loss_date, "<br>",
                                    "<b>", "Cost: ", "</b>$", sub_data$`paid_cost$`, "<br>",
                                    "<b>", "Claim Id: ", "</b> ", sub_data$claim_id, "<br>",
                                    "<b>", "Bus Age: ", "</b> ", sub_data$bus_age, "<br>",
                                    "<b>", "Bus Capacity: ", "</b> ", sub_data$bus_carry_capacity, "<br>",
                                    "<b>","Manufacturer: ", "</b> ", sub_data$asset_manufacturer, "<br>" ),
                       #popupOptions = popupOptions(closeOnClick = TRUE),
      ) %>% leaflet::addLayersControl(baseGroups = c('Streets','Detailed', "Dark"),
                                      options = layersControlOptions(collapsed = FALSE)) %>% 
      addLegend(data = sub_data,"bottomleft", 
                pal = pal,
                # colors = colors,
                values = ~cost_range,
                title = "Cost Levels", 
                opacity = .9)
    
  })
  
  output$summary <- renderText({
    updated_data <- year_data() %>% 
      filter(year_data()$experience_levels == input$experience)
    
    paste("<b>Summary: </b>", "<br>",
          "There are " , dim(updated_data)[1], " incidents in total between these years.")
  })
  output$table1 <- renderTable(spacing = c('xs') ,{
     updated_data <- year_data() %>% 
      filter(year_data()$experience_levels == input$experience)
    updated_data %>% group_by(line_no) %>% summarise(total_cost_line = sum(`paid_cost$`)) %>% 
      data.frame()%>%  drop_na() %>% arrange(desc(total_cost_line)) %>% rename(c("Line No." = "line_no" , "Total Cost" ="total_cost_line" )) %>% head(5) %>% mutate(`Total Cost` = paste('$',formatC(`Total Cost`, big.mark=',', format = 'f')))
  })
  
  output$table2 <- renderTable( spacing = c('xs') ,{
    updated_data <- year_data() %>% 
      filter(year_data()$experience_levels == input$experience)
    updated_data %>% group_by(asset_manufacturer) %>% summarise(total_cost_line = sum(`paid_cost$`)) %>% 
    data.frame() %>% drop_na() %>% arrange(desc(total_cost_line)) %>%  rename(c("Bus Manufact." = "asset_manufacturer", "Total Cost" = "total_cost_line" )) %>% head(5) %>% mutate(`Total Cost` = paste('$',formatC(`Total Cost`, big.mark=',', format = 'f')))
  })
  
  output$table3 <- renderTable( spacing = c('xs') ,{
    updated_data <- year_data() %>% 
      filter(year_data()$experience_levels == input$experience)
    updated_data %>% group_by(city_of_incident) %>% summarise(n = n()) %>% 
    data.frame() %>% drop_na() %>% arrange(desc(n)) %>%  rename(c("City of Incident" = "city_of_incident", "Number of Incident" = "n" )) %>% head(5)
  })
  
  output$plot2 <- renderPlot({
    updated_data <- year_data() %>%
      filter(year_data()$experience_levels == input$experience)
    n <- dim(updated_data)[1]
    updated_data %>% group_by(cost_range) %>%
      summarise(count_cost_range =n()) %>%
      ggplot(aes(x = cost_range, y = count_cost_range, fill = cost_range)) +
      geom_bar(stat= "identity", show.legend = FALSE) + 
      scale_fill_manual(values=c("turquoise2", "steelblue4", "sienna1", "violetred1" )) + 
      coord_flip() + theme_bw() + theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank()) +
      labs(title = "Incident Counts\nby Cost Level", y = "The number of incidents", x= "") 
    
  })
  output$plot1 <- renderPlot({
    updated_data <- year_data() %>% 
      filter(year_data()$experience_levels == input$experience)
    updated_data %>% filter(bus_age > -1  & bus_age < 30 ) %>%
      ggplot(aes(bus_age,color = cost_range, fill = cost_range), alpha = 0.2) + geom_density() + theme_bw() + 
      scale_color_manual(values = c("Level1 (<$200)" = "turquoise2", "Level2 ($200-$1,000)"="steelblue4", "Level3 ($1,000-$10,000)"= "sienna1", "Level4 (>$10,000)" = "violetred1" )) + 
      scale_fill_manual(values = alpha( c("Level1 (<$200)" = "turquoise2", "Level2 ($200-$1,000)"="steelblue4", "Level3 ($1,000-$10,000)"= "sienna1", "Level4 (>$10,000)" = "violetred1" ), 0.1)) + 
      labs(title = "Bus Age Distribution",
           x = 'The age of the buses\nwhen incident happened',
           y = 'The density of bus age') + theme(legend.position = "none")
    
  })
  
   output$plot3 <- renderPlot({
    updated_data <- year_data() %>% 
      filter(year_data()$experience_levels == input$experience)
    updated_data %>% filter(years < 2020) %>%
      ggplot(aes(years ,color = cost_range)) + geom_line(stat='count') + theme_bw() + 
      scale_color_manual(values = c("Level1 (<$200)" = "turquoise2", "Level2 ($200-$1,000)"="steelblue4", "Level3 ($1,000-$10,000)"= "sienna1", "Level4 (>$10,000)" = "violetred1" )) + 
      labs(title = "Incident Counts",
           x = '',
           y = 'The number of incident') + theme(legend.position = "none")
    
  })
  
}


```

```{r , echo = FALSE}
shinyApp(ui2, server2)
```

$~$
  
This dashboard has multiple interactive elements. On the top-left, there are control elements that can be used for filtering the data by incident year and operator experience. Additionally, summary views and the map will update automatically according to what is selected. With the map view, users can zoom in/out and by selecting an individual incident, a popup outlining details about the incident is displayed. The tile control on the upper right corner of the map allows users to change the appearance of the map (switching between street view, details view, and dark view). 
    
<center> <h4>Conclusions and Recommendations</h4> </center>

Some key points that can be seen from the interactive maps are:

- The number of incidents designated as cost level 1 has increased over the years for all of the experience groups. However, the number of incidents for the more severe cost levels has steadily decreased with the exception of cost level 4, which has remained steady.

- The bus age distributions look quite similar for all experience groups and for all cost levels. The distributions are mostly cumulated around 10.

- The percentage of incidents that occur at cost level 4 is almost double for the most experienced operators, which can possibly suggest that experienced operators are involved in more severe incidents.

- When cities are ranked with respect to the number of incidents, Vancouver and Burnaby are always the first and second cities with the most incidents, respectively. However, rankings change quite a bit after this as the experience groups changes. For example, while the third, fourth, and fifth-ranked cities are Surrey, Richmond, and North Vancouver for operators with more than 60 months of experience, it is North Vancouver, Richmond, and Port Coquitlam for operators with less than six months of experience. This matches quite closely with the previous analysis of the operators.
  
- The bus lines with the highest claim costs also vary a lot with operator experience level. Bus lines 320, 20, 99, 4, 22 all have the highest costs for operators with more than 60 months of experience, whereas bus lines 20, 22, 25, 153, and 8 have the highest claim costs for operators with less than 6 months of experience.

<center> <h4>Future Improvements</h4> </center>

The map shows the areas with the most incidents, but it is hard to use the phrase “most dangerous” as the dataset does not tell us how many buses traveled through each area without any incidents. Therefore, certain roads may naturally have more incidents since they are more frequently driven on by TransLink buses. Obtaining how many buses actually operated on any given road over the exact same time period as our data would be ideal but has been noted by TransLink as being practically impossible to obtain. That being said, in the section "Future Analysis" we discuss how the risk of individual roads can be estimated using a machine learning approach very similar to what is already used in this report.
  
### Future Analysis

We outline possible improvements that could further improve this analysis here.

<center> <h4>Causal Interpretations</h4> </center>

TransLink originally approached us with the desire to find **causal** factors that lead to incidents rather than mere correlations. This is very difficult to achieve due to the existence of confounders - variables that influence both the incident risk and a variable of interest like hour of the day. 

These confounders can be controlled for by deliberate experiments. As an example, one such experiment could involve randomly assigning say, 30 randomly selected bus drivers to bus line 10, and 30 randomly selected bus drivers to bus line 16 and recording their number of incidents over time. This is likely very impractical, but would allow TransLink to actually make sound causal claims if they exist.

A more practical approach is in fact an analysis very similar to that of the analysis done in this report - collect as many variables that could reasonably be linked to the likelihood of an incident and analyze everything simultaneously. The only major difference in methodology will be a more proper statistical analysis on the model output shown here or a switch to a more statistical approach like Bayesian statistics (such as what we did with the operators dataset in this report). The problem with this approach when compared to rigorous experiments is that causal claims cannot be made with 100% certainty due to a lack of random assignment that comes with explicit experimentation. At best, causal claims can be strengthened by including as many possible confounders as possible, like what we tried in this report. However, we feel that the analysis done in this report is far from accounting for all possible confounders. Variables such as the steepness of certain roads, road curvature, distractions from billboard signs/buildings, speed of buses leading up to specific incidents, population density/foot traffic of certain areas, and operator preference towards certain lines all could be confounding this analysis badly. To add to this complexity, there are likely multiple interactions between variables (for example, the effect of operator experience on incident risk may change depending on what line the operator is working on) which even further complicates things, though there are modern methods similar in spirit to the methods done in this report where these can be accounted for automatically.

<center> <h4>Roads, Not Just Bus Lines </h4> </center>

Another potential avenue for TransLink to explore is that of incorporating specific roads, rather than just lines. This is entirely possible using the data that we have right now since we are given the specific street names on which an incident actually occurred at. This is more complex than the analysis carried out in this report, but would allow TransLink to potentially modify routes away from high risk streets to avoid incidents. We think that this analysis could be incredibly fruitful for TransLink to have, considering that we know that the biggest determiner of risk is the bus line, and that the worst offending bus lines all happen to move through Downtown Vancouver.

We simply ran out of time to implement this but it is completely possible with small modifications to this analysis.

### References
